<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Disentangling Content and Motion for
Text-Based Neural Video Manipulation">
  <meta name="keywords" content="DiCoMoGAN">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>
      Disentangling Content and Motion for
      Text-Based Neural Video Manipulation
  </title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>


<style type="text/css">

    .figure {
        display: inline-block;
        text-align: center;
    }
    .wrapper {
        margin: 0 auto;
    }

    .pics {
       
        text-align: center;
    }

    .inline {
        width: 15%;
        display: inline-block;
        padding: 0 1px 0 1px;
    }
    .inline2 {
        width: 84%;
        display: inline-block;
        padding: 0 1px 0 1px;
    }
    .inline3 {
        width: 45%;
        display: inline-block;
        padding: 0 1px 0 1px;
    }




</style>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>

</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
                Disentangling Content and Motion for
                Text-Based Neural Video Manipulation
            </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://leventkaracan.github.io">Levent Karacan</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="#">Tolga Kerimoğlu</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="#">İsmail İnan</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://tolgabirdal.github.io">Tolga Birdal</a><sup>3</sup>,
            </span>
            <span class="author-block">
              <a href="https://web.cs.hacettepe.edu.tr/~erkut/">Erkut Erdem</a><sup>4</sup>,
            </span>
            <span class="author-block">
              <a href="https://aykuterdem.github.io/">Aykut Erdem</a><sup>5</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
              <span class="author-block"><sup>1</sup>Iskenderun Technical University,</span>
              <span class="author-block"><sup>2</sup>Bogazici University,</span>
              <span class="author-block"><sup>3</sup>Imperial College London,</span>
              <span class="author-block"><sup>4</sup>Hacettepe University,</span>
              <span class="author-block"><sup>5</sup>Koc University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://bmvc2022.mpi-inf.mpg.de/443/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/2211.02980"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/leventkaracan/dicomogan"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/leventkaracan/dicomogan"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="section">
    <div class="container is-max-desktop">
        <div class="content has-text-justified">
            <a id="table_of_contents"></a>
            <p>
                This page contains qualitative results accompanying our paper. Each set of <b>qualitative results can be accessed with the links below, or simply scroll down</b> to watch the videos in order.
                Specific sequences are linked with buttons for easy reference.</br>

                <ol>
                    <li><a href="#3dshapes">Video Translation on 3D Shapes</a></li>
                    <li><a href="#fashionvideoediting">Video Translation on Fashion Videos</a></li>
                    <li><a href="#disentanglement3dshapes">Disentanglement Quality on 3D Shapes</a></li>
                    <li><a href="#neuralode">Continuous Spatiotemporal Sampling via Neural ODE</a></li>
                    <li><a href="#fashionvideos">Fashion Videos Dataset Overview</a></li>
                </ol>
            </p>
            </div>
        </div>

</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
            <p>
                Giving machines the ability to imagine possible new objects or scenes from linguistic descriptions
                and produce their realistic renderings is arguably one of the most challenging problems in computer vision.
                Recent advances in deep generative models have led to new approaches that give promising results towards this goal.
                In this paper, we introduce a new method called DiCoMoGAN for manipulating videos with natural language,
                aiming to perform local and semantic edits on a video clip to alter the appearances of an object of interest.
                Our GAN architecture allows for better utilization of multiple observations by disentangling content
                and motion to enable controllable semantic edits. To this end, we introduce two tightly coupled networks:
                (i) a representation network for constructing a concise understanding of motion dynamics and temporally invariant content, and
                (ii) a translation network that exploits the extracted latent content representation to actuate the manipulation according to the target description.
                Our qualitative and quantitative evaluations demonstrate that DiCoMoGAN significantly outperforms existing frame-based methods,
                producing temporally coherent and semantically more meaningful results.
            </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="wrapper" >
            <div class="pics">
                <video poster="" id="chair-tp" controls muted playsinline>
                    <source src="./443_video.mp4"
                            type="video/mp4">
                </video>
            </div>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="3dshapes">
    <div class="container is-max-desktop">

        <div class="columns is-centered">



            <!-- Animation. -->
            <div class="columns is-centered" >
                <div class="column is-full-width">
                    <h2 class="title is-3">1. Video Translation on 3D Shapes </h2>

                    <div class="content has-text-justified">
                        <p>
                            Our goal is to perform seamless and semantically meaningful edits on each video frame.
                            Doing so, we need to preserve identity, motion dynamics and description-irrelevant regions intact.
                        </p>
                    </div>

                    <br />


                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"a medium pink sphere" </div>
                            <div class="inline">"a medium green sphere"</div>
                            <div class="inline">"a medium blue sphere"</div>
                            <div class="inline">"a medium red sphere"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/3dshapes/input.gif"/></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/pink_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/green_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/blue_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/red_sphere.gif" /></div>
                        </div>
                    </div>
                    <hr />
                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"a big pink sphere" </div>
                            <div class="inline">"a big green sphere"</div>
                            <div class="inline">"a big blue sphere"</div>
                            <div class="inline">"a big red sphere"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/3dshapes/input.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_pink_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_green_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_blue_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_red_sphere.gif" /></div>
                        </div>
                    </div>
                    <hr />
                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"a medium pink capsule" </div>
                            <div class="inline">"a big green cube"</div>
                            <div class="inline">"a small orange sphere"</div>
                            <div class="inline">"a big red cylinder"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/3dshapes/input.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/medium_pink_capsule.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_green_cube.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/small_orange_sphere.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/3dshapes/big_red_cylinder.gif" /></div>
                        </div>
                    </div>


                    <!--/ Re-rendering. -->

                </div>
            </div>
            <!--/ Animation. -->

        </div>
        </div>
</section>


<section class="section" id="fashionvideoediting">
    <div class="container is-max-desktop">
        <div class="columns is-centered">



            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">2. Video Translation on Fashion Videos</h2>

                    <div class="content has-text-justified">
                        <p>
                            Our goal is to perform seamless and semantically meaningful edits on each video frame.
                            Doing so, we need to preserve identity, motion dynamics and description-irrelevant regions intact.
                        </p>
                    </div>

                    <br />


                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"Red dress with short sleeves" </div>
                            <div class="inline">"Purple dress with short sleeves"</div>
                            <div class="inline">"Green dress with short sleeves"</div>
                            <div class="inline">"Yellow dress with short sleeves"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_rec.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_red.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_purple.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_green.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar.gif" /></div>
                        </div>
                    </div>
                    <hr />
                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"Red dress with long sleeves" </div>
                            <div class="inline">"Purple dress with long sleeves"</div>
                            <div class="inline">"Green dress with long sleeves"</div>
                            <div class="inline">"Yellow dress with long sleeves"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_rec.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_red_long.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_purple_long.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_green_long.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_long.gif" /></div>
                        </div>
                    </div>
                    <hr />
                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline">Input Video</div>
                            <div class="inline">"Red shirts" </div>
                            <div class="inline">"Purple jumpsuits"</div>
                            <div class="inline">"Green shorts"</div>
                            <div class="inline">"Yellow t-shirts"</div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_rec.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_red_shirts.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_purple_jumpsuit.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_green_shorts.gif" /></div>
                            <div class="inline"><img src="./dicomogan_results/fashion/video_1_tar_yellow_tshirts.gif" /></div>
                        </div>
                    </div>


                    <!--/ Re-rendering. -->

                </div>
            </div>
            <!--/ Animation. -->
          </div>
        </div>
</section>

<section class="section" id="disentanglement3dshapes">

    <div class="container is-max-desktop">
        <div class="columns is-centered">



            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">3. Disentanglement Quality on 3D Shapes</h2>

                    <div class="content has-text-justified">
                        <p>
                            DiCoMoGAN learns latent variables depicting highly interpretable concepts decomposed into text relevant, text irrelevant
                            static, and dynamic features. Note that wall and floor colors are not mentioned in the descriptions during training.
                        </p>
                    </div>

                    <br />


                 
                    <div class="wrapper">
                        <div class="inline">
                            <div>Input</div>
                            <br />
                            <br />
                            <div>Reconstruction</div>
                            <br />
                            <br />
                            <div>Object Color</div>
                            <br />
                            <br />
                            <div>Object Shape</div>
                            <br />
                            <br />
                            <div>Object Scale</div>
                            <br />
                            <br />
                            <div>Wall Color</div>
                            <br />
                            <br />
                            <div>Floor Color</div>
                            <br />
                            <br />
                            <div>Dynamic</div>

                        </div>
                        <div class="inline2">
                            <div><img src="./dicomogan_results/3dshapes/disentanglement.gif" /></div>
                        </div>
                    </div>
                    <hr />



                    <!--/ Re-rendering. -->

                </div>
            </div>
            <!--/ Animation. -->

        </div>
    </div>
</section>


<section class="section" id="neuralode">

    <div class="container is-max-desktop">
        <div class="columns is-centered">



            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">4. Continuous Spatiotemporal Sampling via Neural ODE</h2>

                    <div class="content has-text-justified">
                        <p>
                            DiCoMoGAN has an advantage
                            of utilizing latent ODEs that it allows us to interpolate in-between frames over time.
                        </p>
                    </div>

                    <br />

                    <div class="wrapper">
                        <div class="pics">
                            <div>Input Video Frames</div>
                        </div>
                    </div>


                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline3"><img src="./dicomogan_results/3dshapes/ode_1.png" /></div>
                            <div class="inline3"><img src="./dicomogan_results/3dshapes/ode_2.png" /></div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline3">
                                <br />
                                <p>Spatiotemporal Sampling by Neural ODE</p>

                                <p>Here we interpolate 256 frames between first(t=0.0) and last(t=1.0) frames of input video thanks to Latent ODE.</p>
                            </div>
                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline3"><img src="./dicomogan_results/3dshapes/ode_sampling_2.png" /></div>
                            <div class="inline3"><img src="./dicomogan_results/3dshapes/ode_sampling_1.png" /></div>

                        </div>
                    </div>


                    <hr />



                    <!--/ Re-rendering. -->

                </div>
            </div>
            <!--/ Animation. -->

        </div>
    </div>
</section>

<section class="section" id="fashionvideos">

    <div class="container is-max-desktop">
        <div class="columns is-centered">



            <!-- Animation. -->
            <div class="columns is-centered">
                <div class="column is-full-width">
                    <h2 class="title is-3">5. Fashion Videos Dataset Overview</h2>

                    <div class="content has-text-justified">
                        <p>
                            We collected Fashion Videos  dataset from raw videos present in the website of an
                            online clothing retailer by searching products in the cardigans, dresses, jackets, jeans, jumpsuits, shorts, skirts, tops and trousers categories.
                             There are 3178 video clips
                            (approximately 109K distinct frames), which we split into 2579 for training and 598 for
                            testing. 
                        </p>
                        <p>

                            Please do not hesitate to send us an e-mail to access Fashion Videos dataset.
                        </p>
                    </div>

                    <br />


                    <div class="wrapper">
                        <div class="pics">
                            <div class="inline2"><img src="./fashion-category-samples.png" /></div>

                        </div>
                    </div>

                    <div class="wrapper">
                        <div class="pics">
                            <video poster="" id="chair-tp" autoplay controls muted loop playsinline>
                                <source src="./fashion-videos-full.mp4"
                                        type="video/mp4">
                            </video>
                        </div>
                    </div>
                    <hr />



                    <!--/ Re-rendering. -->

                </div>
            </div>
            <!--/ Animation. -->

        </div>
        </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
    @inproceedings{Karacan_2022_BMVC,
    author    = {Levent Karacan and Tolga  Kerimoğlu and İsmail Ata İnan and Tolga Birdal and Erkut Erdem and Aykut Erdem},
    title     = {Disentangling Content and Motion for Text-Based Neural Video Manipulation},
    booktitle = {British Machine Vision Conference (BMVC)},
    year      = {2022}
}
</code></pre>
  </div>
</section>
<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://arxiv.org/pdf/2211.02980.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/leventkaracan/dicomogan" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>
</body>
</html>
